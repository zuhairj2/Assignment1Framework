# -*- coding: utf-8 -*-
"""Jafri Assignment7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UPfyxAAmovp_e8_UNV6s8vyVO_-Cgo-Y

# Initialization, utilities (no TODOs)
"""

import torch
import torchvision
import torch.nn as nn
import argparse
import PIL
import random

def to_list(img):
    return list(map(int, img.view((28*28,)).tolist()))

SCALE_OFF = 0
SCALE_RANGE = 1
SCALE_01 = 2


def show_image(tens, imgname=None, scale=SCALE_01):
    """
    Show an image contained in a tensor. The tensor will be reshaped properly, as long as it has the required 28*28 = 784 entries.

    If imgname is provided, the image will be saved to a file, otherwise it will be stored in a temporary file and displayed on screen.

    The parameter scale can be used to perform one of three scaling operations:
        SCALE_OFF: No scaling is performed, the data is expected to use values between 0 and 255
        SCALE_RANGE: The data will be rescaled from whichever scale it has to be between 0 and 255. This is useful for data in an unknown/arbitrary range. The lowest value present in the data will be
        converted to 0, the highest to 255, and all intermediate values will be assigned using linear interpolation
        SCALE_01: The data will be rescaled from a range between 0 and 1 to the range between 0 and 255. This can be useful if you normalize your data into that range.
    """
    r = tens.max() - tens.min()
    img = PIL.Image.new("L", (28,28))
    scaled = tens
    if scale == SCALE_RANGE:
        scaled = (tens - tens.min())*255/r
    elif scale == SCALE_01:
        scaled = tens*255
    img.putdata(to_list(scaled))
    if imgname is None:
        img.show()
    else:
        img.save(imgname)

"""# Classification (5 TODOs)"""

# Used for both tasks
loss_fn = torch.nn.BCELoss()

# TODO 1: Choose a digit
digit = 4

# TODO 2: Change number of training iterations for classifier
n0 = 20

# TODO 3
# Change Network architecture of the discriminator/classifier network. It should have 784 inputs and 1 output (0 = fake, 1 = real)
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1     = nn.Linear(784, 256)
        self.act1    = nn.LeakyReLU(0.2)
        self.out     = nn.Linear(256, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.act1(self.fc1(x))
        x = self.sigmoid(self.out(x))
        return x

# TODO 4
# Implement training loop for the classifier:
# for i in range(n0):
#     zero gradients
#     calculate predictions for given x
#     calculate loss, comparing the predictions with the given y
#     calculate the gradient (loss.backward())
#     print i and the loss
#     perform an optimizer step
def train_classifier(opt, model, x, y):
    model.train()
    for i in range(n0):
        opt.zero_grad()
        y_pred = model(x)
        loss = loss_fn(y_pred, y)
        loss.backward()
        opt.step()

        # Print epoch and loss
        print(f"[Classifier] Epoch {i+1}/{n0}, Loss = {loss.item():.4f}")

# TODO 5
# Instantiate the network and the optimizer
# call train_classifier with the training set
# Calculate metrics on the validation set
# Example:
#      y_pred = net(x_validation[labels_validation == 3]) calculates all predictions for all images we know to be 3s
#      (y_pred > 0.5) is a tensor that tells you if a given image was classified as your chosen digit (True) or not (False)
#      You can convert this tensor to 0s and 1s by calling .float()
#      (y_pred > 0.5).sum() will tell you how many of these predictions were true
# You are supposed to calculate:
#     For each digit from 0 to 9, which number percentage of images that were of that digit were predicted as your chosen digit
#     The percentage of digits that were classified correctly (i.e. that were your digit and predicted as such, or were another digit and not predicted as your digit)
#     This last value (accuracy) should be over 90% (preferably over 98%; precision and recall may be lower than that, 90-93% would be decent values)
#     Precision (which percentage of images identified as your chosen digit was actually that digit: TP/(TP+FP))
#     Recall (which percentage of your chosen digit was identified as such: TP/(TP+FN))
def classify(x_train, y_train, x_validation, labels_validation):
    # 1) Instantiate network and optimizer
    net = Discriminator()
    opt = torch.optim.Adam(net.parameters(), lr=0.01)

    # 2) Train on the training set
    print("=== Training classifier ===")
    train_classifier(opt, net, x_train, y_train)

    # 3) Evaluate on validation set
    net.eval()

    your = digit
    total_correct = 0
    total_images = x_validation.shape[0]

    # First, get a tensor of predicted labels (0/1) for all validation images
    with torch.no_grad():
        probs = net(x_validation)                # shape: (N_val, 1)
        preds = (probs > 0.5).float().view(-1)   # shape: (N_val,)

    print("\nPer‐digit results (percentage of that digit predicted as your digit):")
    FP = 0  # will accumulate total false positives across all d != your
    TN = 0  # will accumulate total true negatives across all d != your
    TP = 0  # true positives for your digit
    FN = 0  # false negatives for your digit

    for d in range(10):
        mask_d = (labels_validation == d)
        x_d_count = mask_d.sum().item()
        if x_d_count == 0:
            continue

        # Predictions for exactly those indices
        preds_d = preds[mask_d]
        num_pred_as_your = preds_d.sum().item()
        num_pred_not_your = (preds_d == 0).sum().item()

        pct_pred_as_your = 100.0 * num_pred_as_your / x_d_count
        print(f"  Digit {d}: {pct_pred_as_your:.2f}% of {x_d_count} images predicted as {your}")

        if d == your:
            # For your digit: those predicted 1 are true positives; predicted 0 are false negatives
            TP = num_pred_as_your
            FN = num_pred_not_your
        else:
            # For other digits: those predicted 1 are false positives; predicted 0 are true negatives
            FP += num_pred_as_your
            TN += num_pred_not_your

        # Count how many of these images were “correctly classified”:
        if d == your:
            total_correct += num_pred_as_your
        else:
            total_correct += num_pred_not_your

    # 4) Compute overall metrics
    accuracy = 100.0 * total_correct / total_images
    precision = 100.0 * TP / (TP + FP) if (TP + FP) > 0 else 0.0
    recall = 100.0 * TP / (TP + FN) if (TP + FN) > 0 else 0.0

    print(f"\nOverall validation accuracy: {accuracy:.2f}%")
    print(f"Precision (TP / (TP+FP)) = {precision:.2f}%")
    print(f"Recall (TP / (TP+FN))    = {recall:.2f}%")

"""# GAN (5 TODOs)"""

# TODO 6: Change number of total training iterations for GAN, for the discriminator and for the generator
n = 10
n1 = 15
n2 = 15

# TODO 7
# Change Network architecture of the generator network. It should have 100 inputs (will be random numbers) and 784 outputs (one for each pixel, each between 0 and 1)
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        # Input: latent vector of size 100
        self.fc1 = nn.Linear(100, 128)
        self.act1 = nn.LeakyReLU(0.2)
        self.fc2 = nn.Linear(128, 256)
        self.act2 = nn.LeakyReLU(0.2)
        self.fc3 = nn.Linear(256, 512)
        self.act3 = nn.LeakyReLU(0.2)
        self.out = nn.Linear(512, 784)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.act1(self.fc1(x))
        x = self.act2(self.fc2(x))
        x = self.act3(self.fc3(x))
        x = self.sigmoid(self.out(x))
        return x

# TODO 8
# Implement training loop for the discriminator, given real and fake data:
# for i in range(n1):
#     zero gradients
#     calculate predictions for the x known as real
#     calculate loss, comparing the predictions with a tensor consisting of 1s (we want all of these samples to be classified as real)
#     calculate the gradient (loss_true.backward())
#     calculate predictions for the x known as fake
#     calculate loss, comparing the predictions with a tensor consisting of 0s (we want all of these samples to be classified as fake)
#     calculate the gradient (loss_false.backward())
#     print i and both of the loss values
#     perform an optimizer step
# TODO 8: Implement training loop for the discriminator.
def train_discriminator(opt, discriminator, x_true, x_false):
    discriminator.train()
    batch_size = 100

    for i in range(n1):
        opt.zero_grad()

        # 1) Train on real images:
        # If x_true has more than batch_size, sample a random subset:
        if x_true.shape[0] > batch_size:
            idx_real = torch.randperm(x_true.shape[0])[:batch_size]
            real_imgs = x_true[idx_real]
        else:
            real_imgs = x_true
        pred_real = discriminator(real_imgs)
        # Label = 1 for all real
        labels_real = torch.ones_like(pred_real)
        loss_real = loss_fn(pred_real, labels_real)
        loss_real.backward()

        # 2) Train on fake images:
        # Sample a batch of x_false as well (detached)
        if x_false.shape[0] > batch_size:
            idx_fake = torch.randperm(x_false.shape[0])[:batch_size]
            fake_imgs = x_false[idx_fake].detach()
        else:
            fake_imgs = x_false.detach()
        pred_fake = discriminator(fake_imgs)
        labels_fake = torch.zeros_like(pred_fake)
        loss_fake = loss_fn(pred_fake, labels_fake)
        loss_fake.backward()

        # 3) Step optimizer
        opt.step()

        # Print losses
        print(f"[Discriminator] Iter {i+1}/{n1}, Loss_real = {loss_real.item():.4f}, Loss_fake = {loss_fake.item():.4f}")

# TODO 9
# Implement training loop for the generator:
# for i in range(n2):
#     zero gradients
#     generate some random inputs
#     calculate generated images by passing these inputs to the generator
#     pass the generated images to the discriminator to predict if they are true or fake
#     calculate the loss, comparing the predictions with a tensor of 1s (the *generator* wants the discriminator to classify its images as real)
#     calculate the gradient (loss.backward())
#     print i and the loss
#     perform an optimization step
# TODO 9: Implement training loop for the generator:
def train_generator(opt, generator, discriminator):
    generator.train()
    for i in range(n2):
        opt.zero_grad()

        # 1) Sample random noise
        batch_size = 100
        noise = torch.randn((batch_size, 100))  # standard normal

        # 2) Generate fake images from noise
        fake_imgs = generator(noise)

        # 3) Get discriminator’s prediction on these fake images
        pred = discriminator(fake_imgs)

        # 4) Compute loss against “all real” labels (1)
        labels = torch.ones_like(pred)
        loss = loss_fn(pred, labels)
        loss.backward()
        opt.step()

        print(f"[Generator] Iter {i+1}/{n2}, Loss = {loss.item():.4f}")

# TODO 10
# Implement GAN training loop:
# Generate some random images (with torch.rand) as an initial collection of fakes
# Instantiate the two networks and two optimizers (one for each network!)
# for i in range(n):
#    call train_discriminator with the given real images and the collection of fake images
#    call train_generator
#    generate some images with the current generator, and add a random selection of old fake images (e.g. 100 random old ones, and 100new ones = 200 in total)
#    this will be your new collection of fake images
#    save some of the current fake images to a file (use a filename like "sample_%d_%d.png"%(i,j) so you have some samples from each iteration so you can see if the network improves)
# If you read the todos above, your training code will print the loss in each iteration. The loss for the discriminator and the generator should decrease each time their respective training functions are called
# The images should start to look like numbers after just a few (could be after 1 or 2 already, or 3-10) iterations of *this* loop
def gan(x_real):
    show_image(x_real[0], "train_real_0.png", scale=SCALE_01)

    # 2) Instantiate networks and optimizers
    discriminator = Discriminator()
    generator = Generator()
    opt_d = torch.optim.Adam(discriminator.parameters(), lr=0.0005)
    opt_g = torch.optim.Adam(generator.parameters(), lr=0.0005)

    # 3) Initialize fake pool: 100 random images in [0,1]
    x_false = torch.rand((100, 784))  # initial “fake” pool

    # 4) Outer GAN loop
    for epoch in range(n):
        print(f"\n=== GAN Epoch {epoch+1}/{n} ===")

        # 4a) Train the discriminator on current real + fake pools
        train_discriminator(opt_d, discriminator, x_real, x_false)

        # 4b) Train the generator (to fool discriminator)
        train_generator(opt_g, generator, discriminator)

        # 4c)_curate new fake pool_:
        #    - Generate 100 new fakes
        noise_new = torch.randn((100, 100))
        new_fakes = generator(noise_new).detach()
        #    - Keep 100 random old fake images, plus these 100 new ones → 200 total
        keep_idx = torch.randperm(x_false.shape[0])[:100]
        old_kept = x_false[keep_idx].detach()
        x_false = torch.cat([old_kept, new_fakes], dim=0)  # size: [200, 784]

        # 4d) Save a handful of current generator outputs for inspection
        for j in range(10):
            img = new_fakes[j].view(28, 28)
            show_image(img, imgname=f"sample_{epoch}_{j}.png", scale=SCALE_01)

        print(f"Saved 10 generated samples from epoch {epoch}.")

"""# Main (no TODOs)"""

def main(rungan):
    """
    You do not have to change this function!

    It will:
        automatically download the data set if it doesn't exist yet
        make sure all tensor shapes are correct
        normalize the images (all pixels between 0 and 1)
        provide labels for the classification task (0 for all images that are not your digit, 1 for the ones that are)
        extract the images of your chosen digit for the GAN
    """
    train = torchvision.datasets.MNIST(".", download=True)
    x_train = train.data.float().view(-1,28*28)/255.0
    labels_train = train.targets
    y_train = (labels_train == digit).float().view(-1,1)

    validation = torchvision.datasets.MNIST(".", train=False)
    x_validation = validation.data.float().view(-1,28*28)/255.0
    labels_validation = validation.targets

    if rungan:
        gan(x_train[labels_train == digit])
    else:
        classify(x_train, y_train, x_validation, labels_validation)

"""# Test call (TODO: TEST)"""

# NOTE: This will not work until you have done TODO 1 above!
# If you have not done TODO 1 yet, you will get: AttributeError: 'bool' object has no attribute 'float'
GAN = True
main(GAN)